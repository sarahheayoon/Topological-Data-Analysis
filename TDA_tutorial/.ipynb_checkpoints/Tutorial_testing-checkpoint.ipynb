{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56f322fa-6154-41c3-8c85-47ee262985d2",
   "metadata": {},
   "source": [
    "**Welcome to this TESTING notebook!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97548173-df8d-4b90-b517-791d6ff3307c",
   "metadata": {},
   "source": [
    "# Imports and functions\n",
    "\n",
    "Prepare the notebook by running these useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690ae2f-f618-44de-9ce1-b7167e148182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "#from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "import gudhi\n",
    "import gtda # giotto-tda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16442d4-2cb2-4a15-a1de-32d6411d66b5",
   "metadata": {},
   "source": [
    "## Sampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437c05b-c157-47b1-9f62-27d9958650d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions useful to sample different manifolds\n",
    "\n",
    "def sample_sphere(n, dim = 3) :\n",
    "    # uniform sampling of the sphere (works in any dim)\n",
    "    points = np.random.randn(n, dim)\n",
    "    points /= np.linalg.norm(points, axis=1)[:,None]\n",
    "    return points\n",
    "\n",
    "def sample_circle(n) :\n",
    "    # equally spaced : return np.array([[np.cos(2*np.pi*t / n), np.sin(2*np.pi*t / n)] for t in range(n)])\n",
    "    # uniform sampling:\n",
    "    return sample_sphere(n, dim = 2)\n",
    "\n",
    "def sample_helix(n) :\n",
    "    # equally spaced : zline = np.linspace(0, 3, n)\n",
    "    zline = 3*np.random.rand(n)\n",
    "    xline = np.sin(2*np.pi*zline)\n",
    "    yline = np.cos(2*np.pi*zline)\n",
    "    return np.vstack((xline, yline, zline)).T\n",
    "\n",
    "def sample_torus(n, R = 2, r = .5) :\n",
    "    # rejection sampling on a 3D torus, with r <= R\n",
    "    points = np.zeros((n,3))\n",
    "    for k in range(n) :\n",
    "        U,V,W = np.random.rand(3)\n",
    "        theta = 2*np.pi*U ; phi = 2*np.pi*V\n",
    "        while W > (R + r*np.cos(theta)) / (R + r) :\n",
    "            U,V,W = np.random.rand(3)\n",
    "            theta = 2*np.pi*U ; phi = 2*np.pi*V      \n",
    "        points[k] = (R+r*np.cos(theta))*np.cos(phi),(R+r*np.cos(theta))*np.sin(phi),r*np.sin(theta)\n",
    "    return points\n",
    "\n",
    "def sample(n, manif, sigma = 0):\n",
    "    if manif == 'circle' :\n",
    "        points = sample_circle(n)\n",
    "    if manif == 'sphere' :\n",
    "        points = sample_sphere(n)\n",
    "    if manif == 'helix' :\n",
    "        points = sample_helix(n)\n",
    "    if manif == 'torus' :\n",
    "        points = sample_torus(n)\n",
    "    if sigma != 0 :\n",
    "        points += np.random.normal(scale=sigma, size=points.shape)\n",
    "    return points\n",
    "\n",
    "def add_noise(points, sigma, method = 'gaussian') :\n",
    "    n,d = points.shape\n",
    "    if method == 'gaussian' :\n",
    "        return points + np.random.normal(scale=sigma, size=(n,d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a713cb5c-3ec2-40b9-8de8-8360cee7e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom-defined functions to plot point clouds (static)\n",
    "\n",
    "def set_axes_equal_3D(ax): # from StackOverflow my friend\n",
    "    '''Make axes of 3D plot have equal scale so that spheres appear as spheres,\n",
    "    cubes as cubes, etc..  This is one possible solution to Matplotlib's\n",
    "    ax.set_aspect('equal') and ax.axis('equal') not working for 3D.\n",
    "\n",
    "    Input\n",
    "      ax: a matplotlib axis, e.g., as output from plt.gca().\n",
    "    '''\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_middle = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_middle = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_middle = np.mean(z_limits)\n",
    "\n",
    "    # The plot bounding box is a sphere in the sense of the infinity\n",
    "    # norm, hence I call half the max range the plot radius.\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])\n",
    "    \n",
    "def plot_points(points) :\n",
    "    if points.shape[1] == 2 :\n",
    "        plt.figure()\n",
    "        plt.scatter(points[:,0], points[:,1], s=5)\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "    if points.shape[1] == 3 :\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.scatter3D(points[:,0], points[:,1], points[:,2], c=points[:,2], cmap='autumn')\n",
    "        ##ax.set_aspect('equal') # does not work\n",
    "        set_axes_equal_3D(ax)\n",
    "        plt.show()\n",
    "\n",
    "def plot_img(img) :\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img, cmap = 'Oranges', origin = 'lower') # lower to make compatible XY convention of pts and imgs \n",
    "    ax.contour(img, cmap = 'gray_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e163923-916d-477c-b6a9-ebe5cbfc8116",
   "metadata": {},
   "source": [
    "## Compute and show PDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c84078-ec90-4bd7-a27d-6594b220c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to compute persistence diagrams (PDs) extract content from them\n",
    "\n",
    "from gtda.homology import VietorisRipsPersistence, EuclideanCechPersistence, WeakAlphaPersistence, CubicalPersistence\n",
    "from gtda.plotting import plot_diagram as plot_diagrams_plotly, plot_point_cloud as plot_points_plotly\n",
    "\n",
    "def nbpts_PH(diagrams) :\n",
    "    ph0 = len(np.where(np.isclose(diagrams[:,2],0))[0])\n",
    "    ph1 = len(np.where(np.isclose(diagrams[:,2],1))[0])\n",
    "    ph2 = len(np.where(np.isclose(diagrams[:,2],2))[0])\n",
    "    return ph0, ph1, ph2\n",
    "\n",
    "def get_PH_dim(diagrams,dim) :\n",
    "    ph0, ph1, ph2 = nbpts_PH(diagrams)\n",
    "    if dim == 0 :\n",
    "        diag = diagrams[:ph0, :2]\n",
    "    if dim == 1 :\n",
    "        diag = diagrams[ph0:ph0+ph1, :2]\n",
    "    if dim == 2 :\n",
    "        diag = diagrams[ph0 + ph1:, :2]\n",
    "    return diag\n",
    "\n",
    "def get_PH_alldims(diagrams):\n",
    "    ph0, ph1, ph2 = nbpts_PH(diagrams)\n",
    "    PH0 = diagrams[:ph0, :2]\n",
    "    PH1 = diagrams[ph0:ph0+ph1, :2]\n",
    "    PH2 = diagrams[ph0 + ph1:, :2]\n",
    "    return PH0, PH1, PH2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a494057-be5e-4b87-8502-3dd6bf927bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to plot persistence diagrams\n",
    "\n",
    "def plot_diagrams(diagrams, style = 'sep', diagonal = False) :\n",
    "    PH_list = list(get_PH_alldims(diagrams))\n",
    "    col_list = ['#E11033','#1A0DAB','#FF7900']# FBB117\n",
    "    \n",
    "    ph2 = len(PH_list[2])\n",
    "    if ph2 != 0 :\n",
    "        list_dims = [0,1,2]\n",
    "        figsize = (10, 3.5)\n",
    "    else :\n",
    "        list_dims = [0,1]\n",
    "        figsize = (6.5,3.5)\n",
    "    \n",
    "    if diagonal == False :\n",
    "        for dim in list_dims :\n",
    "            PHdim = PH_list[dim]\n",
    "            PH_list[dim] = PHdim[ PHdim[:,0] < PHdim[:,1] ]\n",
    "            \n",
    "    if style == 'sep' :\n",
    "        fig, axes = plt.subplots(1,len(list_dims), figsize = figsize)\n",
    "        for dim in list_dims :\n",
    "            ax = axes[dim]\n",
    "            xmin = PH_list[dim][:,0].min()\n",
    "            ymax = PH_list[dim][:,1].max()\n",
    "            ax.plot([xmin, ymax],[xmin, ymax], c = 'k', alpha = .2, zorder = 1)\n",
    "            ax.scatter(PH_list[dim][:,0], PH_list[dim][:,1], c = col_list[dim], s = 5, zorder = 2)\n",
    "            ax.set_aspect('equal')\n",
    "            ax.set_title('PH{}'.format(dim))\n",
    "            ax.set_xlabel('birth')\n",
    "            ax.set_ylabel('death')\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    if style == 'tog' :\n",
    "        fig = plt.figure(figsize = (4.5,4.5))\n",
    "        xmin = min( [ PH_list[dim][:,0].min() for dim in [0,1,2] ] )\n",
    "        ymax = max( [ PH_list[dim][:,1].max() for dim in [0,1,2] ] )\n",
    "        plt.plot([xmin, ymax],[xmin, ymax], c = 'k',alpha = .2, label='_nolegend_')\n",
    "        for dim in list_dims :\n",
    "            plt.scatter(PH_list[dim][:,0], PH_list[dim][:,1], c = col_list[dim], s = 10)\n",
    "        plt.legend(['PH0','PH1','PH2'])\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def plot_bars(diagrams, diagonal = False) :\n",
    "    ph0, ph1, ph2 = nbpts_PH(diagrams)\n",
    "    PH_list = list(get_PH_alldims(diagrams))\n",
    "    \n",
    "    if ph2 != 0 :\n",
    "        list_dims = [0,1,2]\n",
    "    else :\n",
    "        list_dims = [0,1]\n",
    "        \n",
    "    if diagonal == False :\n",
    "        for dim in list_dims :\n",
    "            PHdim = PH_list[dim]\n",
    "            PH_list[dim] = PHdim[ PHdim[:,0] < PHdim[:,1] ]\n",
    "    \n",
    "    col_list = ['#E11033','#1A0DAB','#FF7900']# FBB117\n",
    "    lab_list = ['PH0','PH1','PH2']\n",
    "    xmax = max([PH_list[dim][:,1].max() for dim in list_dims ] )\n",
    "    delta_y = .01\n",
    "    big_delta_y = .1\n",
    "    ymax = delta_y*(ph0 + ph1 + ph2) + 2*big_delta_y\n",
    "    \n",
    "    fig = plt.figure(figsize = (8, 5))\n",
    "    y = 0 # increment the position of the bar\n",
    "    for dim in list_dims :\n",
    "        for bar in PH_list[dim] :\n",
    "            birth, death = bar\n",
    "            plt.plot([birth, death],[y, y], c = col_list[dim], linewidth = 1)\n",
    "            y += delta_y\n",
    "        y += big_delta_y\n",
    "    plt.axis('equal')\n",
    "    plt.yticks([])\n",
    "    plt.xlim([-10*delta_y,xmax+10*delta_y])\n",
    "    plt.ylim([-10*delta_y,ymax+10*delta_y])\n",
    "    plt.ylabel('persistence bars')\n",
    "    plt.xlabel('filtration value')\n",
    "    fig.tight_layout()\n",
    "    legend_elements = [ Line2D([0], [0], color=col_list[dim], lw=1, label=lab_list[dim]) for dim in list_dims]\n",
    "    plt.legend(handles=legend_elements)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d007da93-f388-4d57-945c-57c78ca89f14",
   "metadata": {},
   "source": [
    "# Data representation and filtration\n",
    "\n",
    "Data produced by the same underlying phenomenon can enjoy multiple representations. The choice of the representation and the filtration of the space can be crucial to revealing different aspects of the phenomenon.\n",
    "\n",
    "These represent the many ways to study data: as images, points, graphs; as continuous or discrete objects; using Rips, Alpha, Cubical complexes, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9f3559-1d50-4ed1-9fd7-7758f5321e09",
   "metadata": {},
   "source": [
    "## Representations of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492e79fd-958a-47cb-91ff-4a79e785a72f",
   "metadata": {},
   "source": [
    "### Points\n",
    "\n",
    "This section shows how to generate 2D or 3D point clouds by sampling various objects / distributions and adding i.i.d. gaussian noise.\n",
    "\n",
    "- 2D point cloud : circle\n",
    "- 3D point cloud : torus, helix, sphere\n",
    "- 2D point cloud : gaussian mixture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49911feb-a493-4b15-9cd7-42fe3b08d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "\n",
    "n = 100 # nb of sampling points\n",
    "sigma = .05 # std of gaussian noise added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739f9cb3-8b36-4e5e-8160-25e3e8bde5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of point cloud in 2D\n",
    "\n",
    "points = sample(n, 'circle', sigma = sigma) # shape (n,dim)\n",
    "plot_points(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dfa5e8-a09f-4a5e-9b10-2b5a5ffa8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three examples of point clouds in 3D\n",
    "\n",
    "for manif in ['torus', 'helix', 'sphere'] :\n",
    "    points = sample(n, manif, sigma = sigma)\n",
    "    plot_points(points)\n",
    "\n",
    "# Uncomment to use giotto-tda's default plotting method\n",
    "# based on Plotly which enables interactive 2D and 3D plots\n",
    "# good for small data but REALLY SLOW for large point clouds\n",
    "# and does not allow to interact with several datasets at a time\n",
    "\n",
    "# plot_points_plotly(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67e03d6-8c55-40a0-838c-5a714cd7623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from a mixture of Gaussians\n",
    "\n",
    "K = 4\n",
    "\n",
    "def random_cov(dim = 2) : # not used\n",
    "    A = np.random.rand(dim,dim) # or choose another randomness, e.g. Wishart distribution\n",
    "    return A @ A.T\n",
    "def random_mu(dim = 2) : # not used\n",
    "    return np.random.randn(dim)\n",
    "#mus = [random_mu() for k in range(K)]\n",
    "#Sigmas = [random_cov() for k in range(K)]\n",
    "#weights = np.random.rand(K)\n",
    "#weights /= weights.sum()\n",
    "\n",
    "mus = np.array([[0,0],[5,0],[3,5],[-2.5,4]])\n",
    "Sigmas = np.array([ [[2,-.5],[-.5,1]],\n",
    "                  [[1,0],[0,1]],\n",
    "                  [[3,-1],[-1,1]],\n",
    "                  [[1,2],[2,5]] ])\n",
    "weights = np.array([0.4, 0.3, 0.2, 0.1]) # should sum to 1\n",
    "print('mus = \\n{}\\nSigmas = \\n{}\\nweights = {}'.format(mus, Sigmas, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a89dc5-6664-4508-8c97-cdb50b0fe6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "\n",
    "def sample_gauss_mixture(n, K, mus, Sigmas, weights, dim = 2) :\n",
    "    points = np.zeros((n, dim))\n",
    "    categs = np.random.choice(K, size=n, p=weights)\n",
    "    for k in range(K) :\n",
    "        points[categs == k] = np.random.multivariate_normal(mus[k], Sigmas[k], size=(categs == k).sum())\n",
    "    return points\n",
    "\n",
    "points = sample_gauss_mixture(n, K, mus, Sigmas, weights)\n",
    "plot_points(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27c4ba5-1abc-4aa3-8e77-a68b56cbf56e",
   "metadata": {},
   "source": [
    "### Images\n",
    "\n",
    "There is a very nice and natural link between points and images: a distribution can be represented by $N$ sample points as well as an image sampling its density function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc635f-eced-49ca-838f-2a48c351991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mixture of Gaussians as an image\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "YY,XX = np.mgrid[-4:9:.05, -5:8:.05 ] # manually decided extremal x an y values based on scattered points\n",
    "grid = np.dstack((XX,YY)) \n",
    "\n",
    "def img_gauss_mixture(grid, K, mus, Sigmas, weights) :\n",
    "    img = 0\n",
    "    for k in range(K) :\n",
    "        var_k = multivariate_normal(mean=mus[k], cov=Sigmas[k])\n",
    "        img += weights[k] * var_k.pdf(grid)\n",
    "    return img\n",
    "\n",
    "img = img_gauss_mixture(grid, K, mus, Sigmas, weights) \n",
    "\n",
    "plot_img(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b28ff3-65c0-4859-b4a2-aee248e83335",
   "metadata": {},
   "source": [
    "## Rips, Alpha, Cubical complexes and filtrations\n",
    "\n",
    "This section introduces you to 3 very useful types of complexes used in numerical computations.\n",
    "\n",
    "- the Rips and Alpha complexes for point clouds\n",
    "- the cubical complex for images\n",
    "\n",
    "The Rips complex is easy to compute numerically as it only depends on pairwise distances. On the other hand, the Čech and the Alpha complexes satisfy the nice property of being homotopy equivalent to the ball cover of the point cloud, and their PH is all the same. But as the dimension of the space grows, it becomes more difficult to the Čech and Alpha complexes, contrarily to the Rips complex. The max dimension of simplices in the Alpha complex is naturally that of the space, whereas it can grow for the Rips complex.\n",
    "\n",
    "Alpha complexes are generally preferred over Čech complexes as the latter are more difficult to compute.\n",
    "\n",
    "Notes:\n",
    "- this section does not cover the Witness and Čech complexes (implemented in gudhi and giotto).\n",
    "- gudhi is used instead of giotto to visualize the simplicial complexes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b9500-6cae-47b0-93d1-8615d15e916d",
   "metadata": {},
   "source": [
    "### Rips vs Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad884fbb-a0a3-4c27-9ec9-e5f4fc020102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simp(points, edges, triangles, ax = None) :\n",
    "    '''Plots simplicial complex in 2D, up to triangles of dim 2.\n",
    "    points = np.array([[x1,y1], [x2,y2], ... ])\n",
    "    edges = np.array([ [pt1, pt2], [pt3, pt4], ... ])\n",
    "    tri = np.array([ [pt1, pt2, pt3], [pt4, pt5, pt6], ... ])\n",
    "    where pti = corresponding index in the list of pts. '''\n",
    "    \n",
    "    if ax is None :\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "    ax.scatter(points[:,0],points[:,1])\n",
    "    for edge in edges :\n",
    "        ax.plot(points[edge,0], points[edge,1], 'k') #plt.plot([pts[A,0], pts[B,0]], [pts[A,1], pts[B,1]])\n",
    "    for tri in triangles :\n",
    "        ax.fill(points[tri,0], points[tri,1], 'r', alpha=0.1)\n",
    "    #if tetras is not None :\n",
    "    #    for tet in tetras :\n",
    "    #        ax.fill(points[tet,0], points[tet,1], 'b', alpha=0.2)\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "def build_Rips(points, r):\n",
    "    skeleton = gudhi.RipsComplex(points = points, max_edge_length = r)\n",
    "    simplex_tree = skeleton.create_simplex_tree(max_dimension = 2)\n",
    "    print('Rips nb vertices:', simplex_tree.num_vertices())\n",
    "    print('Rips nb simplices:', simplex_tree.num_simplices())\n",
    "    #compute list of simplices: #rips_generator = simplex_tree.get_filtration()\n",
    "    edges = np.array([s[0] for s in simplex_tree.get_skeleton(1) if len(s[0]) == 2 ])\n",
    "    results = [edges]\n",
    "    triangles = np.array([s[0] for s in simplex_tree.get_skeleton(2) if len(s[0]) == 3 ])\n",
    "    results += [triangles]\n",
    "    #tetras = np.array([s[0] for s in simplex_tree.get_skeleton(3) if len(s[0]) == 4 ])\n",
    "    #results += [tetras]\n",
    "    return tuple(results) # [ edges, triangles ]\n",
    "\n",
    "def build_Alpha(points, max_alpha_square):\n",
    "    alpha_complex = gudhi.AlphaComplex(points = points)\n",
    "    simplex_tree = alpha_complex.create_simplex_tree(max_alpha_square = max_alpha_square)\n",
    "    print('Alpha nb vertices:', simplex_tree.num_vertices())\n",
    "    print('Alpha nb simplices:', simplex_tree.num_simplices())\n",
    "    #compute list of simplices: #rips_generator = simplex_tree.get_filtration()\n",
    "    edges = np.array([s[0] for s in simplex_tree.get_skeleton(1) if len(s[0]) == 2 ])\n",
    "    results = [edges]\n",
    "    triangles = np.array([s[0] for s in simplex_tree.get_skeleton(2) if len(s[0]) == 3 ])\n",
    "    results += [triangles]\n",
    "    #if points.shape[1] >= 3 :\n",
    "    #    tetras = np.array([s[0] for s in simplex_tree.get_skeleton(3) if len(s[0]) == 4 ])\n",
    "    #    results += [tetras]\n",
    "    return tuple(results) # [ edges, triangles ]\n",
    "\n",
    "def plot_Rips(points, r, ax = None) :\n",
    "    simplices = build_Rips(points, r)\n",
    "    plot_simp(points,*simplices, ax = ax)\n",
    "\n",
    "def plot_Alpha(points, max_alpha_square, ax = None) :\n",
    "    simplices = build_Alpha(points, max_alpha_square)\n",
    "    plot_simp(points,*simplices, ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8cbbce-2bb5-4290-9df4-430612e9ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with loose scattered points (otherwise everything quickly becomes clamped)\n",
    "\n",
    "points = np.random.rand(20,2) # not too much points otherwise useless visualization\n",
    "\n",
    "plot_points(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4fd691-bceb-4219-96c1-19b30d286044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot two simplicial complexes built on top of the same point cloud\n",
    "# for a given filtration value\n",
    "\n",
    "value = 0.3 # filtration value\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize = (8,4))\n",
    "\n",
    "# Vietoris-Rips or Rips complexes\n",
    "ax = axes[0]\n",
    "plot_Rips(points, r = 2*value, ax = ax) # scaling applied to gudhi's parameter\n",
    "ax.set_title('Rips complex for val = {}'.format(value))\n",
    "\n",
    "# Alpha complexes\n",
    "ax = axes[1]\n",
    "ax.set_title('Alpha complex for val = {}'.format(value))\n",
    "plot_Alpha(points, max_alpha_square = value**2, ax = ax) # scaling applied to gudhi's parameter\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa9890d-de5a-46f4-be5a-fab776a2e525",
   "metadata": {},
   "source": [
    "***Question**: what can you say on the Rips and Alpha complexes?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733edc73-a992-471d-8c3c-558f4481a20e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cubical\n",
    "\n",
    "Cubical complexes are the natural setting for representing images as complexes and for studying their persistence.\n",
    "\n",
    "The maximal cells are square pixels for 2D images, cubic voxels for 3D images.\n",
    "The filtration value of any cubical cell is the minimum of the filtration values of the maximal cells that contain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f025a-1f8e-4f4c-bf4a-9516455fc0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's re-use a point cloud and an image generated with a mixture of Gaussians in the previous section.\n",
    "\n",
    "points = sample_gauss_mixture(100, K, mus, Sigmas, weights)\n",
    "plot_points(points)\n",
    "\n",
    "img = img_gauss_mixture(grid, K, mus, Sigmas, weights) \n",
    "plot_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaaa350-d8a3-4339-a06e-83539dbcbdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot different complexes built on top of the same density\n",
    "\n",
    "value = 0.8 # filtration value for Rips and Alpha complexes\n",
    "value2 = 0.1 * img.max() \n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize = (10,4))\n",
    "\n",
    "# Rips complex\n",
    "ax = axes[0]\n",
    "plot_Rips(points, r = 2*value, ax = ax) # scaling applied to gudhi's parameter\n",
    "ax.set_title('Rips complex for val = {}'.format(value))\n",
    "\n",
    "# Alpha complexe\n",
    "ax = axes[1]\n",
    "ax.set_title('Alpha complex for val = {}'.format(value))\n",
    "plot_Alpha(points, max_alpha_square = value**2, ax = ax) # scaling applied to gudhi's parameter\n",
    "\n",
    "# Cubical complex\n",
    "ax = axes[2]\n",
    "ax.set_title('Cubical complex for img >= {}'.format(value2))\n",
    "suplevel = img >= value2\n",
    "ax.imshow(suplevel, origin = 'lower', cmap = 'gray')\n",
    "print('Cubical nb 2D cubes: {}'.format(np.size(suplevel)))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d001da-3c69-44dd-a1a4-6960da8cae68",
   "metadata": {},
   "source": [
    "The simplicial complexes are shown next to the cubical complex for illustration purpose. These are different ways to analyze the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9299d-c177-463a-abf4-9cd77c9668aa",
   "metadata": {},
   "source": [
    "# Persistence diagrams and computation\n",
    "\n",
    "We saw how to generate point clouds and images, and how to build various complexes on top of them.\n",
    "These complexes allow us to study the suspected homology of the underlying geometric object.\n",
    "\n",
    "However, one complex correspond to a fixed scale. But what happens if we change the filtration value?\n",
    "How does the homology of the complex change?\n",
    "\n",
    "The answer is justly given by computing **persistent homology**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aa1a90-e454-4e90-962b-3622d02b08a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute PH for a single point cloud\n",
    "\n",
    "Let's start with a single point cloud and compute its persistence diagrams based on a filtration.\n",
    "\n",
    "- compute the **Rips PH** (giotto)\n",
    "- plot it using 3 methods:\n",
    "    - **diagram** (scattered dots), custom function\n",
    "    - **barcode** (bars), custom function\n",
    "    - **interactive diagram**, with plotly (but slow for large data)\n",
    "- compute the **Čech** (giotto) and **Alpha** PH (gudhi).\n",
    "\n",
    "Čech persistence is slower to compute than Rips persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558bf05c-9d85-458f-bdbb-56ede6dc78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a single point cloud\n",
    "\n",
    "n = 100\n",
    "sigma = .05\n",
    "\n",
    "points = sample(n, 'torus', sigma = sigma)\n",
    "plot_points(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1da99b-0350-43a1-8321-2ca90ec66ef3",
   "metadata": {},
   "source": [
    "**Important**: provide `VietorisRipsPersistence.fit_transform()` in giotto with a list of point clouds.\n",
    "Here the list is reduced to a singleton.\n",
    "\n",
    "`diagrams` consists in an array of shape `(ph0 + ph1 + ph2, 3)`.\n",
    "`diagrams` is a vertical stack of all the (birth, death, dim) bars, ordered by increasing dim.\n",
    "Thus, `diagrams[:,0]` and `diagrams[:,1]` (1st and 2nd columns) specify the birth and death times\n",
    "while `diagrams[:,2]` has values in `[0,1,2]` and specifies the homology dimension of the persistence bar.\n",
    "\n",
    "Note: by default in giotto, the first PH0 bar whose death = infinity (never dies) is discarded. This can be changed in the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e482eabc-9252-4267-8ea0-ee614147313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with Rips filtration: compute Rips PDs (PH0, PH1, PH2) for this point cloud\n",
    "\n",
    "VR = VietorisRipsPersistence(homology_dimensions=[0, 1, 2])\n",
    "diagrams = VR.fit_transform([points])[0] # take single element from list\n",
    "print('Shape of diagrams is {}'.format(diagrams.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8df66e-c98d-4508-bed3-500ef65e4f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show portions of the diagrams\n",
    "\n",
    "ph0, ph1, ph2 = nbpts_PH(diagrams)\n",
    "PH0, PH1, PH2 = get_PH_alldims(diagrams)\n",
    "print('There are {} pts in PH0, {} in PH1 and {} in PH2 \\n'.format(ph0,ph1,ph2))\n",
    "\n",
    "print('PH0 starts with ...')\n",
    "print(PH0[:5],'...')\n",
    "print('PH1 starts with ...')\n",
    "print(PH1[:5],'...')\n",
    "print('PH2 starts with ...')\n",
    "print(PH2[:5],'...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256e04d5-61e1-470a-bb4c-b87749bea5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot diagrams: several ways to visualize them\n",
    "\n",
    "# By default, plot_diagrams() and plot_bars() ignore diagonal elements \n",
    "# for which birth = death (unless you specify diagonal = True)\n",
    "\n",
    "# PD as scattered points (birth, death) with death >= birth\n",
    "plot_diagrams(diagrams, style = 'tog') \n",
    "# style = 'tog' to plot 3 homology dimensions together, style = 'sep' to plot separately\n",
    "\n",
    "# PD as persistence bars [ (birth, y) --- (death, y) ]\n",
    "plot_bars(diagrams)\n",
    "\n",
    "# Uncomment to use giotto-tda's default plotting method\n",
    "# based on Plotly which enables interactive 2D and 3D plots\n",
    "# good for small data but REALLY SLOW for large point clouds\n",
    "# and does not allow to interact with several datasets at a time\n",
    "\n",
    "plot_diagrams_plotly(diagrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672a70cb-fcf6-4ce3-b7bf-63f99f15bf83",
   "metadata": {},
   "source": [
    "***Question**: comment on the aspect of PH0, PH1, and PH2. In particular, what do the bars correspond to?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9993c1-8131-49d8-a879-65cf14640846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Alpha PD for this point cloud\n",
    "\n",
    "# use gudhi's Alpha PD computation\n",
    "# Alpha not implemented in giotto, but a variant - WeakAlpha - is\n",
    "\n",
    "alpha_complex = gudhi.AlphaComplex(points)\n",
    "simplex_tree = alpha_complex.create_simplex_tree()\n",
    "result_str = 'Alpha complex is of dimension ' + repr(simplex_tree.dimension()) + ' - ' + \\\n",
    "    repr(simplex_tree.num_simplices()) + ' simplices - ' + \\\n",
    "    repr(simplex_tree.num_vertices()) + ' vertices.'\n",
    "print(result_str)\n",
    "diag = simplex_tree.persistence()\n",
    "\n",
    "# Convert diag to a giotto-like convention\n",
    "\n",
    "birth_death = np.vstack([np.array(diag[k][1:]) for k in range(len(diag)) ])\n",
    "homo_dims = np.array([diag[k][0] for k in range(len(diag))])\n",
    "aux = np.hstack((birth_death, homo_dims[:,None]))\n",
    "aux = aux[np.argsort(aux[:,2])]\n",
    "# by default (as in giotto), delete the first PH0 bar that never dies and death = infinity\n",
    "alpha_diagrams = np.delete(aux, np.where(aux[:,1] == np.inf)[0], axis = 0)\n",
    "print('Shape of alpha_diagrams is {}'.format(alpha_diagrams.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81056015-53f3-4992-b249-e01973069e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Cech PD for this point cloud (SLOW)\n",
    "\n",
    "#Cech = EuclideanCechPersistence(homology_dimensions=[0, 1, 2])\n",
    "#cech_diagrams = Cech.fit_transform([points])[0] \n",
    "#print('Shape of cech_diagrams is {}'.format(cech_diagrams.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727738b3-e05f-46e7-b403-238dfa4d5cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_diagrams(diagrams, style = 'sep')\n",
    "#print('Rips')\n",
    "#plot_diagrams(alpha_diagrams, style = 'sep')\n",
    "#print('Alpha')\n",
    "#plot_diagrams(cech_diagrams, style = 'sep')\n",
    "#print('Cech')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704d6acf-894d-44cc-896d-aee2db3dd43e",
   "metadata": {},
   "source": [
    "## Compute PH for several point clouds\n",
    "\n",
    "Actually giotto-tda offers the possibility to compute PDs in *parallel*.\n",
    "This is handy if it comes to comparing several point clouds.\n",
    "\n",
    "Let's compute the Rips PH for nine 3D point clouds: 3 torus, 3 helix, 3 sphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c9b7f3-b84e-4661-b97f-9749e7a68754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble data as a list of point clouds\n",
    "\n",
    "m = 3 # number of point clouds per type of manifold\n",
    "manifolds = np.hstack((['torus']*m, ['helix']*m, ['sphere']*m))\n",
    "clouds = np.vstack( [ sample(n, manifolds[i], sigma = sigma)[None] for i in range(len(manifolds)) ] )\n",
    "print('Shape of clouds is {}'.format(clouds.shape))\n",
    "\n",
    "# Uncomment below to show the individual point clouds \n",
    "\n",
    "#for i in range(len(clouds)) :\n",
    "#    plot_points(clouds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3614bdd2-2ebd-4ee1-a95b-206476adbcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PDs (PH0, PH1, PH2) for all point clouds in parallel\n",
    "\n",
    "VR = VietorisRipsPersistence(homology_dimensions=[0, 1, 2])\n",
    "diagrams_list = VR.fit_transform(clouds)\n",
    "print('Shape of diagrams_list is {}'.format(diagrams_list.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5ca61-374c-4010-b825-cc8d1de3dc92",
   "metadata": {},
   "source": [
    "**Warning**: `diagrams_list` is a `np.array` stacking the persistence diagrams of all the point clouds,\n",
    "with individual diagrams being themselves a vertical stack of all the `(birth, death, dim)` bars,\n",
    "ordered by increasing homology dim.\n",
    "\n",
    "Bars for which `birth = death` (diagonal elts) may be artificially introduced during giotto-tda's \n",
    "computation for padding purposes. Thus, all point cloud are attributed diagrams of the same shape, while it is obviously not true that there is the same number non-diagonal elements from shape to shape.\n",
    "Diagonal elements carry no information and hence should be effectively ignored by any further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b662b3e-f6e2-462c-802c-08ad658fad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 9 diagrams together\n",
    "\n",
    "for i in range(9) :\n",
    "    plot_diagrams(diagrams_list[i], style = 'sep') \n",
    "    print('{} for i = {}'.format(manifolds[i], i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4b11e0-68f7-4a55-8943-1553fb6102d8",
   "metadata": {},
   "source": [
    "***Question**: try to spot differences and similarities between the diagrams of the shapes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28420f9f-a305-4541-b2fc-8ea076edec25",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute PH for an image\n",
    "\n",
    "Given an image, we can study the cubical persistence of its sup-level sets $f^{-1}[t, \\infty)$ or sub-level sets $f^{-1}(-\\infty,t]$. Sup-level sets are especially interesting to visualize for density-like images.\n",
    "\n",
    "In giotto's `CubicalPersistence()`, use `homology_dimensions = [0,1]` for a 2D image and `homology_dimensions = [0,1,2]` for a 3D image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3a13f-4c9e-4183-9459-1c7cc8c66e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cubical persistence of the  an image - let's take again the img generated from previous section.\n",
    "\n",
    "Cub = CubicalPersistence(homology_dimensions=[0, 1])\n",
    "img_diagrams = Cub.fit_transform([-img])[0] \n",
    "print('Shape of img_diagrams is {}'.format(img_diagrams.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc743ccc-fa2b-493d-9963-fc09171d2df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = np.array([.8,.4,.2,.05,0.001])\n",
    "\n",
    "fig, axes = plt.subplots(1,len(levels), figsize = (len(levels)*3,3))\n",
    "\n",
    "for i in range(len(levels)) :\n",
    "    axes[i].imshow(img >= levels[i] * img.max(), cmap = 'gray')\n",
    "    axes[i].set_title('lev = {:.1f} % of max'.format(100*levels[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c742de3f-65f9-431a-a53a-cee75612dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_diagrams(img_diagrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dfe127-cfc4-4010-b588-c5db7afb7504",
   "metadata": {},
   "source": [
    "***Question**: interpret the diagrams.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe76cc1f-dbb1-4fed-89ec-9b748ef1ae24",
   "metadata": {},
   "source": [
    "## Distances between PDs\n",
    "\n",
    "To compare persistence diagrams, let's try 3 distances:\n",
    "- bottleneck distance\n",
    "- Wasserstein distance\n",
    "- landscape distance\n",
    "\n",
    "They enjoy a property of stability, meaning that two point clouds or two images close enough give similar diagrams.\n",
    "\n",
    "*However, the reverse is not true*: having similar diagrams does not necessarily mean that the shapes are the same (see the dangerous counter-examples in the slides)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e33551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtda.diagrams as PD\n",
    "\n",
    "## bottleneck distance \n",
    "delta = 0.1\n",
    "# When delta equal to 0., an exact algorithm is used; \n",
    "# otherwise, a faster approximate algorithm is used and symmetry is not guaranteed.\n",
    "# smaller delta gives more precise value\n",
    "bottleneck = PD.PairwiseDistance(metric='bottleneck',\n",
    "                      metric_params={'delta': delta},\n",
    "                      order=None)\n",
    "\n",
    "## wasserstein distance\n",
    "L_p = 2\n",
    "delta = 0.2 # no exact algorithm\n",
    "\n",
    "wasserstein = PD.PairwiseDistance(metric='wasserstein',\n",
    "                              metric_params={'delta': delta, 'p': L_p},\n",
    "                              order=None)\n",
    "\n",
    "## L_2 distance between landscapes\n",
    "L_p = 1\n",
    "n_bins = 1000\n",
    "n_layers = 5\n",
    "\n",
    "landscape = PD.PairwiseDistance(metric='landscape',\n",
    "                                 metric_params={'p': L_p, 'n_bins': n_bins, 'n_layers': n_layers},\n",
    "                                 order=None)\n",
    "\n",
    "bottleneck_distance = bottleneck.fit_transform(diagrams_list) # compute pairwise distance \n",
    "wasserstein_distance = wasserstein.fit_transform(diagrams_list)\n",
    "landscape_distance = landscape.fit_transform(diagrams_list)\n",
    "\n",
    "bottleneck_distance.shape \n",
    "# (i,j,:) a vector of bottleneck distance in each homology dimension for diagram i and j\n",
    "\n",
    "# visualize the heatmap of distance matrix in homology dimension 1\n",
    "fig, axes = plt.subplots(1,3, figsize = (12,4))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.imshow(bottleneck_distance[:, :, 1], cmap='hot')\n",
    "ax.set_title('bottleneck distance')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.imshow(wasserstein_distance[:, :, 1], cmap='hot')\n",
    "ax.set_title('2-wasserstein distance')\n",
    "\n",
    "ax = axes[2]\n",
    "ax.imshow(landscape_distance[:, :, 1], cmap='hot')\n",
    "ax.set_title('1-landscape distance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('3 torus, 3 helix, 3 spheres')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102fcf63-1121-48fe-a10c-c3eec8284f0c",
   "metadata": {},
   "source": [
    "***Question**: can you justify the distances between the 3 groups of shapes?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9327bbfd-7ea4-4b87-86fb-54858322867c",
   "metadata": {},
   "source": [
    "## Vectorization of PDs\n",
    "\n",
    "PDs can be handled as vectors instead of diagrams. This section introduces you to:\n",
    "- persistence landscapes\n",
    "- persistence images\n",
    "- Betti curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49866b89-aa3b-49c5-885b-03c0f3c77049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization of PDs\n",
    "\n",
    "## persistence landscapes \n",
    "n_layers = 3 # show lambda_k for k = 1,2,3\n",
    "n_bins = 500 # number of grids to approximate a function\n",
    "PL = PD.PersistenceLandscape(n_layers=n_layers, n_bins=n_bins)\n",
    "landscape_list = PL.fit_transform(diagrams_list)\n",
    "landscape_list.shape\n",
    "\n",
    "## plot the landscape for the second diagram up to dimension 1\n",
    "PL.plot(landscape_list, sample=1, homology_dimensions=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49c83b5-766b-4dc1-b21d-cb7d765b4b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## persistence images\n",
    "\n",
    "sigma = 0.1 # std of Gaussian kernel\n",
    "n_bins = 500 # number of grids to approximate a function\n",
    "PI = PD.PersistenceImage(sigma=sigma, n_bins=n_bins)\n",
    "PI_list = PI.fit_transform(diagrams_list)\n",
    "PI.plot(PI_list, sample=3, homology_dimension_idx=1, colorscale='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86b351-4edd-46b2-9cfd-648764a00b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Betti curves\n",
    "\n",
    "n_bins = 500\n",
    "BC = PD.BettiCurve(n_bins=n_bins)\n",
    "BC_list = BC.fit_transform(diagrams_list)\n",
    "BC.plot(BC_list, sample=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c01115-8ffe-4612-ad4f-2c85b80ab38f",
   "metadata": {},
   "source": [
    "# Last Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8519dda-98d1-41d9-9dd6-b1ad636f0707",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Good! Every cell has been run correctly.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
